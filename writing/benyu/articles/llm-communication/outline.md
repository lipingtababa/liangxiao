# 文章大纲：如何与LLM有效协作

## 核心论点
有效的AI协作需要专业的沟通技能——具体性、基于信息的反馈，以及人类判断、LLM生成、软件强制执行之间的战略性分工。

---

## 1. Hook: 4小时调试悖论

**数据呈现：**
- 编码时间 ↓ 33%（2H → 5min）
- 但调试时间仍然是 4H
- 迭代频率 ↑ 9倍（3天一次 → 一天三次）
- **问题：生产力提升不明确**

**引出疑问：** 为什么AI写代码更快了，但调试时间没有改善？

---

## 2. Problem: 常见沟通错误

**展示8个高频但低效的prompt：**

1. "用中文回答我"
2. "生成完整代码"
3. "还是无法运行"
4. "帮我修改代码"
5. "你的代码还是有问题"
6. "请不要添加不必要的注释"
7. "只生成我让你生成的部分"
8. "都说了参考我之前的代码"

**分析为什么这些无效：**
- "还是无法运行" → LLM无法从这句话推导出具体错误信息
- "生成完整代码" → 没有明确范围
- "你的代码还是有问题" → 情绪化表达，零可执行信息

**理论基础：信息论的不可逆性**

这种情形和香农的信息论基础一样：信息传递有方向性。

类比：给朋友指路
- ✓ "在星巴克左转，走200米到红色大楼" → 朋友能找到
- ✗ "往那边走" + 手势 → 信息不可逆，事后无法复现

和LLM沟通也是一样：
- ✓ `TypeError: Cannot read property 'map' of undefined at line 47` → LLM能推导"运行失败"
- ✗ "还是无法运行" → LLM无法逆向推导具体错误

**关键洞察：这不是工程，这是祈祷**

看看这些prompt：
- "还是无法运行"
- "帮我修改代码"
- "你的代码还是有问题"

这些听起来像什么？**像在对着阿拉丁神灯许愿。**

你不会这样跟同事沟通：
> "嘿，小王，那个bug还是没修好。"
> （然后期待小王自己去猜是哪个bug，什么error message，在哪个文件）

但很多人就是这样跟LLM说话的。

**类比：芝麻开门 vs 工程规格**

问题在于，很多人在不知不觉中把prompt当作咒语：
- ❌ "芝麻开门！" （magical spell）
- ❌ "神灯精灵，给我一个完美的代码！" （prayer）
- ❌ "还是不行" （emotional complaint）

但LLM需要的是工程规格：
- ✅ `AuthController.ts:47: TypeError: req.user is undefined` （specification）
- ✅ "补全第45-67行的auth逻辑，确保所有endpoints检查JWT token" （requirement）
- ✅ "这个方案有性能问题，换用方案B：缓存+lazy loading" （technical decision）

**核心问题：混淆了"许愿"和"协作"**

我们习惯了对搜索引擎"许愿"（输入几个关键词，期待它理解你的意图）。但LLM协作不是搜索，而是**工程协作**。

不管你用Claude、GPT-4还是什么未来模型，只要香农信息论还成立，零信息量的输入就不可能产生有价值的输出。

**换句话说：用对神灯许愿的方式跟工程师沟通，结果就是4小时调试。**

---

## 3. Solution: 有效沟通的三大原则

**对比展示：坏prompt vs 好prompt**

### 原则1：具体性（Specificity）
- ❌ "生成完整代码"
- ✅ "把auth部分补全，并且确保所有需要保护的endpoints都检查authorization"

### 原则2：信息优于情绪（Information over Emotion）
- ❌ "还是无法运行"
- ✅ [粘贴具体的error message]

**关键：** 信息是不对称的
```
Error message → LLM能推导出"还是无法运行" ✓
"还是无法运行" → LLM无法推导出error message ✗
```

### 原则3：战略性重定向（Strategic Redirection）
**朋友的真实案例：**
> "你已经连续三次修改失败了，你不应该在这个根因上钻牛角尖试探，而应该系统审视架构合理性来寻找解决问题方案"

**类比：像专业经理一样给反馈**
- 明确要求（scope + constraints + success criteria）
- 建设性反馈（具体问题 + 改进方向）
- 必要时提供战略层面的重定向

---

## 4. Broader Framework: 人类-LLM-工具的分工协作

### 核心原则：强制执行 > 教育（Enforcement > Education）

**固定的、不可违背的规则 → 用软件强制执行，不要依赖LLM遵守**

| 问题 | 错误做法 | 正确做法 |
|------|----------|----------|
| LLM修改测试用例 | 教育它"不要作弊" | 文件系统权限：测试用例只读 |
| LLM push到main | 告诉它"别这样" | GitHub branch protection |
| LLM用`git add -A` | 调教它用正确命令 | Pre-commit hook禁止 |

### 为什么这样做？
- **LLM是概率性的** - 可能"忘记"或"决定"打破规则
- **软件执行是确定性的** - 100%可靠
- **节省认知负担** - 不用反复"提醒"LLM

### 什么应该沟通给LLM？
- 权衡取舍、上下文、判断性决策
- "如果性能重要用方案A，如果可读性重要用方案B"

### 什么应该用软件强制？
- 绝对规则、格式要求、安全边界

**关键洞察：** 分工是场景特定的，不是固定的。决定如何分工本身就是一项技能。

---

## 5. Case Study: Notion + LLM数学辅导

**背景：具体的数字**
- 孩子：12岁，瑞典6年级，需要英文数学辅导
- 每周辅导1-2次
- 历史数据：Notion数据库中60+次辅导记录
- 涉及主题：分数、小数、几何、百分比、代数初步
- 目标：复习6年级 + 为7年级做准备（但不能超前太多）

**为什么这个案例重要？**

不同于简单的"一次性代码生成"场景，这是一个**持续的、多方协作的、有质量要求的**真实应用。

### 失败的尝试：一开始怎么做错的

**第一次尝试（失败）：**
```
Prompt: "给我孩子出10道6年级数学题"
```
**结果：**
- 难度不对（有些太简单，有些包含7年级内容）
- 格式不统一（有些有答案，有些没有）
- 无法追踪历史（下次辅导重复相同主题）

**第二次尝试（依然失败）：**
```
Prompt: "出题要按瑞典大纲，不要太简单，留答题空间"
```
**结果：**
- 仍然出现7年级内容
- "答题空间"被理解为在题目下面留几行（打印后不够用）
- 没有基于历史表现调整难度

**问题根源：**
试图用"教育"的方式让LLM理解所有约束，但约束太多、太模糊。

类比：这就像告诉一个新同事"不要写烂代码"——完全无法执行。

### 成功的方案：三方分工

**用流程图展示协作模式**
[插入diagram-swimlane.pdf截图]

### 人类职责（判断）：
- **决定学习目标**（复习6年级 or 特定主题）
  - 例：本周发现孩子对分数除法还不熟练 → 增加这类题目
- **审核并确认**出题计划
  - LLM会提交如："10道题，其中4道分数除法，3道几何，3道百分比"
  - 人类判断是否合理
- **评估题目质量**
  - 检查是否符合大纲
  - 确认难度适中
- **批改、讲解、教学**
  - 这是核心价值，不可替代

### LLM职责（生成）：
- **分析学生历史表现**（从Notion数据）
  - 读取过去10次辅导记录
  - 识别薄弱主题
- **创建评估和出题计划**
  - 提出题目分布建议
  - 等待人类批准
- **生成题目**（英文、可打印格式）
  - 严格遵循瑞典6年级大纲
  - 格式：每题后留足答题空间（具体指定5cm高度）
- **保存到Notion DB**
  - 记录日期、主题标签、难度

### 工具（Notion/打印机/纸笔）职责（强制执行）：
- **Notion数据库结构**强制：
  - 必填字段：日期、主题、难度级别
  - 标准化标签：只能选择预定义主题
  - 历史记录自动按时间排序
- **打印机**：物理输出（A4，单面）
- **纸笔**：让孩子手写答题（重要的认知过程）

### 关键突破点：具体约束的具体表达

**原来的模糊指令：**
> "留答题空间"

**现在的具体指令：**
> "每道题后插入一个5cm高的空白区域。使用Markdown语法：`<div style='height:5cm'></div>`。确保打印在A4纸上时，每页最多3道题。"

**原来的模糊约束：**
> "不要超出6年级范围"

**现在的强制约束：**
> "使用Notion数据库的'大纲主题'属性，只能选择：分数运算、小数、百分比、基础几何、测量单位。如果你建议的题目涉及代数方程或函数，我会拒绝。"

### 沟通原则的体现：

**具体性：**
- 不是："给孩子出点题"
- 而是：12岁、6年级复习+7年级预习、瑞典大纲、英文、可打印、每题后5cm空白、不要包含7年级上学期内容

**信息优于情绪：**
- 提供Notion数据库链接（60+历史记录）
- LLM分析：上次辅导中分数除法错误率60% → 本次增加练习
- 不需要人类"记得"或"解释"薄弱点

**战略性工作流：**
- 多步骤：评估 → 计划 → **人类审核** → 确认 → 生成
- 关键检查点：计划阶段人类批准
- 防止浪费：不会生成20道题后才发现难度不对

**强制执行 > 教育：**
- ✗ 教育LLM "不要选7年级内容" → 概率性服从
- ✓ Notion标签只包含6年级主题 → 100%强制
- ✗ 要求"留足空间" → 理解模糊
- ✓ 指定`<div style='height:5cm'></div>` → 精确执行

### 数据对比：改进前后

| 指标 | 改进前 | 改进后 |
|------|--------|--------|
| 题目可用率 | ~40% | ~95% |
| 调整轮次 | 平均3-4轮 | 平均1轮 |
| 准备时间 | 30-45分钟 | 8-12分钟 |
| 难度匹配度 | 主观评估"一般" | 基于数据，客观适配 |

**关键洞察：**

这个案例验证了文章的核心论点——有效协作不是"调教"LLM，而是：
1. 用专业方式沟通（具体、信息化）
2. 战略性分工（人类判断，LLM生成，工具强制）
3. 持续优化（基于数据调整）

---

## 总结

**核心信息：**
与LLM有效协作不是学习新技能，而是应用现有的专业标准。

**生动类比：LLM是高级但不完美的实习生**

想象你管理一个极其聪明但经验不足的实习生：
- 他能快速完成任务 → 但需要清晰的指令
- 他能推理和创造 → 但会遗忘或曲解规则
- 他能处理复杂工作 → 但需要检查点和反馈

你不会对实习生说："还是不行"，然后期待他猜到问题所在。
你也不会每天早上重复"别push到main分支"，而是设置branch protection。

**和LLM协作也是一样。**

**三个层次：**
1. **基础层：** 专业沟通（具体、信息化、战略性）
   - 就像和资深工程师沟通一样清晰具体
2. **系统层：** 聪明分工（人类判断 vs LLM生成 vs 软件执行）
   - 判断 = 人类，生成 = LLM，执行 = 工具
3. **实践层：** 场景特定的决策（什么时候用哪种方式）
   - 每个项目、每个任务需要不同的分工策略

**行动建议：**
- **下次给LLM指令时，问自己："我会这样跟资深同事说吗？"**
- **识别绝对规则 → 用软件强制，别浪费token**
  - 例：pre-commit hooks, branch protection, file permissions
- **保留沟通带宽用于真正需要判断的地方**
  - 例：架构决策，权衡取舍，业务逻辑

**最后的挑战：**

回到开头的4小时调试悖论——如果你仍然花4小时调试，问题可能不在AI，而在你的沟通方式。

试试这个：下次调试时，把你的每一条prompt写下来。如果你不好意思把这些prompt展示给同事看，那就是你该改进的地方。

**换句话说：**
- AI写代码的速度已经提升了10倍
- 但如果你的沟通效率是0.1倍
- 最终生产力还是没变

提升沟通，才能真正释放AI的潜力。

---

## 待补充材料

**数据需求（需要真实数据，不可编造）：**
- [ ] 4小时调试悖论的具体数字来源
  - 编码时间减少33%（2H → 5min）的数据来自哪里？
  - 调试时间4H是平均值还是某个具体案例？
  - 迭代频率提升9倍的计算依据？
  - **如果没有真实数据，改为：**"我观察到一个现象..."或用占位符

- [ ] 把8个低效prompt改写成有效版本（section 3）
  - 每个低效prompt后面都要加上对应的有效版本

- [ ] 数学辅导案例的补充细节
  - [ ] 插入diagram-swimlane.pdf截图到section 5
  - [ ] 确认"60+次辅导记录"的真实性
  - [ ] 确认"题目可用率40% → 95%"的数据来源
  - [ ] 确认"准备时间30-45分钟 → 8-12分钟"是否准确

**内容增强：**
- [ ] Section 2: 为每个低效prompt添加"如果跟同事这样说会怎样"的对比
- [ ] Section 4: 补充更多enforcement vs education的实例
  - 例：代码格式（用prettier强制 vs 教育LLM）
  - 例：commit message格式（用commitlint vs 提醒LLM）

**读者互动：**
- [ ] 在文末添加：
  - "你在和LLM协作时遇到过哪些沟通问题？欢迎留言分享。"
  - "如果你有更好的enforcement策略，也欢迎讨论。"
  - "这篇文章对你有帮助吗？点赞和转发让更多人看到。"

---

## 风格检查清单

按照style_guide.md检查：

**Specificity（具体性）：**
- [x] 具体数字：4H调试，33%减少，9倍迭代，60+记录
- [x] 具体公司/产品：Claude Code, GPT-4, Notion, GitHub
- [x] 具体场景：瑞典6年级数学，A4纸打印，5cm空白
- [ ] 需补充：引用朋友的名字？（可选）

**Argumentation（论证）：**
- [x] 理论基础：香农信息论
- [x] 类比：永动机，指路，实习生
- [x] 对比：坏prompt vs 好prompt，改进前后数据
- [x] 提供解决方案：三大原则 + 分工框架

**Style（风格）：**
- [x] 开场hook：4小时调试悖论
- [x] 反问句："你会这样跟同事说吗？"
- [x] 自我引用："我的朋友"案例
- [x] 结尾挑战：写下你的prompt，敢给同事看吗？
- [x] 中英混用：Software Development, pre-commit hooks, branch protection
- [ ] 考虑添加：更多sarcastic tone对烂prompt的吐槽（可选）

**Engagement（互动）：**
- [ ] 需要在文末添加明确的engagement call-to-action
