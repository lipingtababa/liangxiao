#!/usr/bin/env python3
"""
ç«¯åˆ°ç«¯é›†æˆæµ‹è¯• - æµ‹è¯•å®Œæ•´çš„ç¿»è¯‘ç®¡é“
"""

import pytest
import json
import sys
import tempfile
from pathlib import Path
from datetime import datetime
from unittest.mock import Mock, patch, MagicMock
import os

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from extract_content_with_state import extract_from_html, extract_from_url, process_incremental
from state_manager import ArticleStateManager
from markdown_generator import generate_markdown, batch_generate
from image_processor import ImageProcessor


class TestPipelineIntegration:
    """ç®¡é“é›†æˆæµ‹è¯•ç±»"""

    @pytest.fixture
    def complete_html_article(self):
        """å®Œæ•´çš„HTMLæ–‡ç« å†…å®¹"""
        return """
        <!DOCTYPE html>
        <html lang="zh-CN">
        <head>
            <meta charset="UTF-8">
            <meta property="og:title" content="ç‘å…¸ç”Ÿæ´»å®Œå…¨æŒ‡å—ï¼šä»ç§»æ°‘åˆ°å®šå±…">
            <meta property="og:description" content="è¯¦ç»†ä»‹ç»åœ¨ç‘å…¸ç”Ÿæ´»çš„æ–¹æ–¹é¢é¢">
            <meta name="author" content="ç‘å…¸é©¬å·¥">
        </head>
        <body>
            <div class="rich_media_area_primary">
                <div class="rich_media_content" id="js_content">
                    <h1 class="rich_media_title">ç‘å…¸ç”Ÿæ´»å®Œå…¨æŒ‡å—ï¼šä»ç§»æ°‘åˆ°å®šå±…</h1>
                    <div class="rich_media_meta_list">
                        <em class="rich_media_meta">ç‘å…¸é©¬å·¥</em>
                        <em class="rich_media_meta">2024-01-20</em>
                    </div>

                    <p><strong>å‰è¨€</strong></p>
                    <p>ç§»å±…ç‘å…¸æ˜¯äººç”Ÿçš„é‡å¤§å†³å®šã€‚æœ¬æ–‡å°†ä¸ºæ‚¨æä¾›ä»ç”³è¯·ç­¾è¯åˆ°åœ¨ç‘å…¸å®‰å®¶çš„å®Œæ•´æŒ‡å—ã€‚</p>

                    <h2>ç¬¬ä¸€éƒ¨åˆ†ï¼šç­¾è¯å’Œå±…ç•™è®¸å¯</h2>
                    <p>ç‘å…¸çš„ç§»æ°‘ä½“ç³»ç›¸å¯¹é€æ˜å’Œé«˜æ•ˆã€‚ä¸»è¦çš„å±…ç•™è®¸å¯ç±»å‹åŒ…æ‹¬ï¼š</p>
                    <ul>
                        <li>å·¥ä½œå±…ç•™è®¸å¯</li>
                        <li>å­¦ç”Ÿå±…ç•™è®¸å¯</li>
                        <li>å®¶åº­å›¢èšå±…ç•™è®¸å¯</li>
                        <li>è‡ªé›‡å±…ç•™è®¸å¯</li>
                    </ul>

                    <img src="https://example.com/visa-types.jpg" alt="ç‘å…¸ç­¾è¯ç±»å‹" data-ratio="0.75">

                    <h2>ç¬¬äºŒéƒ¨åˆ†ï¼šä½æˆ¿</h2>
                    <p>åœ¨ç‘å…¸æ‰¾æˆ¿å­å¯èƒ½æ˜¯æœ€å¤§çš„æŒ‘æˆ˜ä¹‹ä¸€ï¼Œç‰¹åˆ«æ˜¯åœ¨æ–¯å¾·å“¥å°”æ‘©ã€å“¥å¾·å ¡å’Œé©¬å°”é»˜ç­‰å¤§åŸå¸‚ã€‚</p>

                    <h3>ç§Ÿæˆ¿å¸‚åœº</h3>
                    <p>ç‘å…¸çš„ç§Ÿæˆ¿å¸‚åœºåˆ†ä¸ºä¸€æ‰‹åˆåŒå’ŒäºŒæ‰‹åˆåŒï¼š</p>
                    <ol>
                        <li><strong>ä¸€æ‰‹åˆåŒï¼ˆFÃ¶rstahandskontraktï¼‰</strong>ï¼šç›´æ¥ä¸æˆ¿ä¸œæˆ–ä½æˆ¿å…¬å¸ç­¾è®¢</li>
                        <li><strong>äºŒæ‰‹åˆåŒï¼ˆAndrahandskontraktï¼‰</strong>ï¼šä»æ‹¥æœ‰ä¸€æ‰‹åˆåŒçš„ç§Ÿå®¢å¤„è½¬ç§Ÿ</li>
                    </ol>

                    <blockquote>
                        <p>æç¤ºï¼šåœ¨BostadsfÃ¶rmedlingenæ’é˜Ÿæ˜¯è·å¾—ä¸€æ‰‹åˆåŒçš„ä¸»è¦é€”å¾„ï¼Œä½†ç­‰å¾…æ—¶é—´å¯èƒ½é•¿è¾¾8-10å¹´ã€‚</p>
                    </blockquote>

                    <img data-src="https://example.com/apartment-interior.jpg" alt="å…¸å‹çš„ç‘å…¸å…¬å¯“">

                    <h2>ç¬¬ä¸‰éƒ¨åˆ†ï¼šå·¥ä½œå’Œç¨åŠ¡</h2>
                    <p>ç‘å…¸çš„å°±ä¸šå¸‚åœºå¯¹å¤–å›½äººç›¸å¯¹å¼€æ”¾ï¼Œç‰¹åˆ«æ˜¯ITã€å·¥ç¨‹å’ŒåŒ»ç–—é¢†åŸŸã€‚</p>

                    <h3>ä¸ªäººå·ç ï¼ˆPersonnummerï¼‰</h3>
                    <p>ä¸ªäººå·ç æ˜¯åœ¨ç‘å…¸ç”Ÿæ´»çš„å…³é”®ã€‚æœ‰äº†ä¸ªäººå·ç ï¼Œæ‚¨å¯ä»¥ï¼š</p>
                    <ul>
                        <li>å¼€è®¾é“¶è¡Œè´¦æˆ·</li>
                        <li>ç­¾è®¢æ‰‹æœºåˆåŒ</li>
                        <li>æ³¨å†ŒåŒ»ç–—æœåŠ¡</li>
                        <li>ç”³è¯·å„ç§ä¼šå‘˜å¡</li>
                    </ul>

                    <h3>ç¨åŠ¡ç³»ç»Ÿ</h3>
                    <p>ç‘å…¸çš„ç¨ç‡è¾ƒé«˜ï¼Œä½†ç›¸åº”çš„ç¤¾ä¼šç¦åˆ©ä¹Ÿå¾ˆå®Œå–„ã€‚ç¨ç‡æ ¹æ®æ”¶å…¥æ°´å¹³åˆ†ä¸ºä¸åŒæ¡£æ¬¡ï¼š</p>
                    <table>
                        <tr><th>å¹´æ”¶å…¥ï¼ˆSEKï¼‰</th><th>è¾¹é™…ç¨ç‡</th></tr>
                        <tr><td>0 - 509,300</td><td>çº¦32%</td></tr>
                        <tr><td>509,300 - 735,600</td><td>çº¦52%</td></tr>
                        <tr><td>735,600ä»¥ä¸Š</td><td>çº¦57%</td></tr>
                    </table>

                    <img src="https://example.com/tax-calculation.png" alt="ç‘å…¸ç¨åŠ¡è®¡ç®—">

                    <h2>ç¬¬å››éƒ¨åˆ†ï¼šç¤¾ä¼šç¦åˆ©</h2>
                    <p>ç‘å…¸çš„ç¤¾ä¼šç¦åˆ©ä½“ç³»ä¸–ç•Œé—»åï¼ŒåŒ…æ‹¬ï¼š</p>
                    <ul>
                        <li><strong>åŒ»ç–—ä¿å¥</strong>ï¼šå‡ ä¹å…è´¹çš„åŒ»ç–—æœåŠ¡</li>
                        <li><strong>è‚²å„¿å‡</strong>ï¼š480å¤©çš„å¸¦è–ªè‚²å„¿å‡</li>
                        <li><strong>å„¿ç«¥æ´¥è´´</strong>ï¼šæ¯æœˆ1250å…‹æœ—/å­©å­</li>
                        <li><strong>æ•™è‚²</strong>ï¼šä»å°å­¦åˆ°å¤§å­¦çš„å…è´¹æ•™è‚²</li>
                    </ul>

                    <h2>ç¬¬äº”éƒ¨åˆ†ï¼šè¯­è¨€å­¦ä¹ </h2>
                    <p>è™½ç„¶å¤§å¤šæ•°ç‘å…¸äººè‹±è¯­å¾ˆå¥½ï¼Œä½†å­¦ä¹ ç‘å…¸è¯­å¯¹èå…¥ç¤¾ä¼šè‡³å…³é‡è¦ã€‚</p>
                    <p>æ”¿åºœæä¾›å…è´¹çš„ç‘å…¸è¯­è¯¾ç¨‹ï¼ˆSFI - Svenska fÃ¶r invandrareï¼‰ç»™æ‰€æœ‰ç§»æ°‘ã€‚</p>

                    <img data-src="https://example.com/sfi-classroom.jpg" alt="SFIè¯¾å ‚">

                    <h2>æ€»ç»“</h2>
                    <p>ç§»å±…ç‘å…¸éœ€è¦å……åˆ†çš„å‡†å¤‡å’Œè€å¿ƒã€‚è™½ç„¶åˆæœŸå¯èƒ½é¢ä¸´å„ç§æŒ‘æˆ˜ï¼Œä½†ç‘å…¸çš„é«˜è´¨é‡ç”Ÿæ´»ã€å®Œå–„çš„ç¤¾ä¼šä¿éšœå’Œå‹å¥½çš„ç¤¾ä¼šç¯å¢ƒï¼Œä½¿è¿™é‡Œæˆä¸ºè®¸å¤šäººç†æƒ³çš„å±…ä½åœ°ã€‚</p>

                    <p><em>å¸Œæœ›è¿™ä»½æŒ‡å—å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ã€‚ç¥æ‚¨åœ¨ç‘å…¸ç”Ÿæ´»æ„‰å¿«ï¼</em></p>
                </div>
            </div>
        </body>
        </html>
        """

    @pytest.fixture
    def temp_workspace(self):
        """åˆ›å»ºä¸´æ—¶å·¥ä½œç©ºé—´"""
        with tempfile.TemporaryDirectory() as tmpdir:
            workspace = Path(tmpdir)
            (workspace / "posts").mkdir()
            (workspace / "images").mkdir()
            (workspace / "data").mkdir()
            yield workspace

    @pytest.mark.integration
    def test_complete_pipeline_flow(self, complete_html_article, temp_workspace):
        """æµ‹è¯•å®Œæ•´çš„å¤„ç†æµç¨‹"""
        # 1. æå–å†…å®¹
        extracted_data = extract_from_html(complete_html_article)

        assert extracted_data["title"] == "ç‘å…¸ç”Ÿæ´»å®Œå…¨æŒ‡å—ï¼šä»ç§»æ°‘åˆ°å®šå±…"
        assert extracted_data["author"] == "ç‘å…¸é©¬å·¥"
        assert len(extracted_data["images"]) == 4
        assert "ç­¾è¯å’Œå±…ç•™è®¸å¯" in extracted_data["content"]["text"]
        assert "ç¤¾ä¼šç¦åˆ©" in extracted_data["content"]["text"]

        # 2. çŠ¶æ€ç®¡ç†
        state_file = temp_workspace / "data" / "state.json"
        state_manager = ArticleStateManager(str(state_file))

        url = "https://mp.weixin.qq.com/s/test-article"
        extracted_data["original_url"] = url

        # æ·»åŠ åˆ°çŠ¶æ€ç®¡ç†
        success = state_manager.add_article(url, extracted_data)
        assert success is True

        # éªŒè¯çŠ¶æ€
        assert state_manager.is_article_processed(url)
        article_state = state_manager.get_article_state(url)
        assert article_state["status"] == "completed"

        # 3. ç”ŸæˆMarkdown
        markdown_result = generate_markdown(
            extracted_data,
            temp_workspace / "posts"
        )

        assert markdown_result["success"] is True
        assert markdown_result["file_path"] is not None

        # éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶
        markdown_file = Path(markdown_result["file_path"])
        assert markdown_file.exists()

        content = markdown_file.read_text(encoding="utf-8")
        assert "ç‘å…¸ç”Ÿæ´»å®Œå…¨æŒ‡å—" in content
        assert "---" in content  # frontmatter
        assert "![" in content  # å›¾ç‰‡å¼•ç”¨

    @pytest.mark.integration
    def test_incremental_processing(self, temp_workspace):
        """æµ‹è¯•å¢é‡å¤„ç†æœºåˆ¶"""
        state_file = temp_workspace / "data" / "state.json"
        state_manager = ArticleStateManager(str(state_file))

        # æ¨¡æ‹Ÿæ–‡ç« æ•°æ®
        articles = [
            {
                "url": f"https://example.com/article{i}",
                "data": {
                    "title": f"æ–‡ç« {i}",
                    "author": "ä½œè€…",
                    "content": {"text": f"å†…å®¹{i}" * 100},
                    "images": []
                }
            }
            for i in range(5)
        ]

        # ç¬¬ä¸€æ¬¡å¤„ç†
        for article in articles[:3]:
            state_manager.add_article(article["url"], article["data"])

        # è·å–æœªå¤„ç†çš„URLs
        all_urls = [a["url"] for a in articles]
        unprocessed = state_manager.get_unprocessed_urls(all_urls)

        assert len(unprocessed) == 2
        assert articles[3]["url"] in unprocessed
        assert articles[4]["url"] in unprocessed

    @pytest.mark.integration
    @patch('requests.get')
    def test_image_processing_integration(self, mock_get, temp_workspace):
        """æµ‹è¯•å›¾ç‰‡å¤„ç†é›†æˆ"""
        # æ¨¡æ‹Ÿå›¾ç‰‡å“åº”
        mock_response = Mock()
        mock_response.content = b"fake image data"
        mock_response.status_code = 200
        mock_get.return_value = mock_response

        processor = ImageProcessor(str(temp_workspace / "images"))

        # å¤„ç†HTMLä¸­çš„å›¾ç‰‡
        html = """
        <div class="rich_media_content">
            <img src="http://example.com/image1.jpg" alt="å›¾ç‰‡1">
            <img data-src="http://example.com/image2.jpg" alt="å›¾ç‰‡2">
        </div>
        """

        processed_html, image_mapping = processor.process_article_images(
            html, "test-article"
        )

        assert len(image_mapping) == 2
        for mapping in image_mapping:
            assert "original_url" in mapping
            assert "local_path" in mapping

    @pytest.mark.integration
    def test_error_recovery(self, temp_workspace):
        """æµ‹è¯•é”™è¯¯æ¢å¤æœºåˆ¶"""
        state_file = temp_workspace / "data" / "state.json"
        state_manager = ArticleStateManager(str(state_file))

        # æ ‡è®°é”™è¯¯
        error_url = "https://example.com/error-article"
        state_manager.mark_article_error(error_url, "ç½‘ç»œé”™è¯¯")

        # éªŒè¯é”™è¯¯çŠ¶æ€
        article_state = state_manager.get_article_state(error_url)
        assert article_state["status"] == "error"
        assert article_state["error"] == "ç½‘ç»œé”™è¯¯"

        # ç»Ÿè®¡åº”è¯¥åæ˜ é”™è¯¯
        stats = state_manager.get_statistics()
        assert stats["error_articles"] == 1

    @pytest.mark.integration
    def test_batch_processing(self, temp_workspace):
        """æµ‹è¯•æ‰¹é‡å¤„ç†"""
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        articles = []
        for i in range(10):
            articles.append({
                "title": f"æ‰¹é‡æ–‡ç« {i+1}",
                "author": "æµ‹è¯•ä½œè€…",
                "publish_date": "2024-01-20",
                "content": {
                    "text": f"è¿™æ˜¯ç¬¬{i+1}ç¯‡æ–‡ç« çš„å†…å®¹ã€‚" * 50,
                    "html": f"<p>è¿™æ˜¯ç¬¬{i+1}ç¯‡æ–‡ç« çš„HTMLå†…å®¹ã€‚</p>"
                },
                "images": []
            })

        # ä¿å­˜ä¸ºJSON
        json_file = temp_workspace / "data" / "articles.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(articles, f, ensure_ascii=False, indent=2)

        # æ‰¹é‡ç”Ÿæˆ
        results = batch_generate(str(json_file), str(temp_workspace / "posts"))

        # éªŒè¯ç»“æœ
        assert len(results) == 10
        success_count = sum(1 for r in results if r["success"])
        assert success_count == 10

        # éªŒè¯æ–‡ä»¶ç”Ÿæˆ
        generated_files = list((temp_workspace / "posts").glob("*.md"))
        assert len(generated_files) == 10

    @pytest.mark.integration
    def test_content_update_detection(self, temp_workspace):
        """æµ‹è¯•å†…å®¹æ›´æ–°æ£€æµ‹"""
        state_file = temp_workspace / "data" / "state.json"
        state_manager = ArticleStateManager(str(state_file))

        url = "https://example.com/article"
        original_data = {
            "title": "åŸå§‹æ ‡é¢˜",
            "content": {"text": "åŸå§‹å†…å®¹"},
            "images": []
        }

        # æ·»åŠ åŸå§‹æ–‡ç« 
        state_manager.add_article(url, original_data)

        # ç›¸åŒå†…å®¹ä¸éœ€è¦æ›´æ–°
        assert not state_manager.needs_update(url, "åŸå§‹å†…å®¹")

        # ä¿®æ”¹åçš„å†…å®¹éœ€è¦æ›´æ–°
        assert state_manager.needs_update(url, "ä¿®æ”¹åçš„å†…å®¹")

    @pytest.mark.integration
    @pytest.mark.slow
    def test_large_article_processing(self, temp_workspace):
        """æµ‹è¯•å¤§å‹æ–‡ç« å¤„ç†"""
        # åˆ›å»ºå¤§å‹æ–‡ç« 
        large_content = "è¿™æ˜¯ä¸€æ®µå¾ˆé•¿çš„å†…å®¹ã€‚" * 1000  # çº¦15000å­—ç¬¦

        large_article = {
            "title": "è¶…é•¿æ–‡ç« æµ‹è¯•",
            "author": "æµ‹è¯•ä½œè€…",
            "content": {
                "text": large_content,
                "html": f"<p>{large_content}</p>"
            },
            "images": [
                {"src": f"http://example.com/img{i}.jpg", "alt": f"å›¾{i}"}
                for i in range(20)  # 20å¼ å›¾ç‰‡
            ]
        }

        # ç”ŸæˆMarkdown
        result = generate_markdown(large_article, temp_workspace / "posts")

        assert result["success"] is True
        assert result["metadata"]["word_count"] > 10000
        assert result["metadata"]["image_count"] == 20

    @pytest.mark.integration
    def test_special_characters_handling(self, temp_workspace):
        """æµ‹è¯•ç‰¹æ®Šå­—ç¬¦å¤„ç†"""
        special_html = """
        <div class="rich_media_content">
            <h1 class="rich_media_title">æ ‡é¢˜åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼š&amp; &lt; &gt; &quot; &#39; Â© Â® â„¢</h1>
            <p>å†…å®¹åŒ…å«emojiï¼šğŸ˜€ ğŸ‰ ğŸš€</p>
            <p>ä¸­æ–‡æ ‡ç‚¹ï¼šï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š""''</p>
            <p>æ•°å­¦ç¬¦å·ï¼šÂ± Ã— Ã· â‰ˆ â‰  â‰¤ â‰¥</p>
        </div>
        """

        extracted = extract_from_html(special_html)
        result = generate_markdown(extracted, temp_workspace / "posts")

        assert result["success"] is True

        # è¯»å–ç”Ÿæˆçš„æ–‡ä»¶
        if result["file_path"]:
            content = Path(result["file_path"]).read_text(encoding="utf-8")
            # åº”è¯¥ä¿ç•™ç‰¹æ®Šå­—ç¬¦
            assert "emoji" in content or "ğŸ˜€" in content

    @pytest.mark.integration
    def test_concurrent_processing(self, temp_workspace):
        """æµ‹è¯•å¹¶å‘å¤„ç†"""
        import threading
        import time

        state_file = temp_workspace / "data" / "state.json"
        state_manager = ArticleStateManager(str(state_file))

        results = []
        lock = threading.Lock()

        def process_article(index):
            """å¤„ç†å•ä¸ªæ–‡ç« çš„çº¿ç¨‹å‡½æ•°"""
            article_data = {
                "title": f"å¹¶å‘æ–‡ç« {index}",
                "content": {"text": f"å†…å®¹{index}"},
                "images": []
            }

            url = f"https://example.com/concurrent{index}"
            success = state_manager.add_article(url, article_data)

            with lock:
                results.append((index, success))

        # åˆ›å»ºå¹¶å¯åŠ¨çº¿ç¨‹
        threads = []
        for i in range(10):
            thread = threading.Thread(target=process_article, args=(i,))
            threads.append(thread)
            thread.start()

        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()

        # éªŒè¯ç»“æœ
        assert len(results) == 10
        assert all(r[1] for r in results)  # æ‰€æœ‰æ“ä½œéƒ½åº”è¯¥æˆåŠŸ

        # éªŒè¯çŠ¶æ€æ–‡ä»¶
        stats = state_manager.get_statistics()
        assert stats["total_articles"] == 10

    @pytest.mark.integration
    def test_cleanup_mechanism(self, temp_workspace):
        """æµ‹è¯•æ¸…ç†æœºåˆ¶"""
        from datetime import timedelta

        state_file = temp_workspace / "data" / "state.json"
        state_manager = ArticleStateManager(str(state_file))

        # æ·»åŠ æ–‡ç« å¹¶ä¿®æ”¹æ—¶é—´
        for i in range(5):
            url = f"https://example.com/old{i}"
            data = {"title": f"æ—§æ–‡ç« {i}", "content": {"text": "å†…å®¹"}, "images": []}
            state_manager.add_article(url, data)

            # ä¿®æ”¹å‰3ä¸ªä¸ºæ—§æ–‡ç« 
            if i < 3:
                old_date = (datetime.now() - timedelta(days=35)).isoformat()
                state_manager.state_data["articles"][url]["last_processed_at"] = old_date
                state_manager._save_state()

        # æ¸…ç†30å¤©å‰çš„æ–‡ç« 
        removed = state_manager.cleanup_old_entries(30)

        assert removed == 3
        assert len(state_manager.state_data["articles"]) == 2


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-m", "integration"])