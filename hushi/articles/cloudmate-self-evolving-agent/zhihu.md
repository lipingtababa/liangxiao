## 自我进化的软件：CloudMate 的自适应路径探索与知识生成机制

## 引言：从规则维护到端到端进化

上个月,我们有幸邀请到了腾讯云 CloudMate 智能运维系统负责人兆祥进行在线分享。分享会中讨论了一个核心命题:在不断变化的生产环境中,如何构建一个能够适应未知故障的 Agent 系统?

随着大模型能力的提升,将 AI 融入开发生产环境已成定局。然而,运维场景具有高度的动态性:系统架构和代码逻辑都在不断变更。一个静态的 Agent 无论在部署时多么强大,随着时间推移,其预设知识库与实际环境的偏差必然会导致能力衰退。

面对这一挑战,当前的工程实践主要分为两个流派:

第一派是"自底向上"的知识工程流派。这一派试图通过精细化的知识管理来应对变化。工程师需要设计复杂的知识图谱,在每次版本发布时同步更新文档和规则。然而,这种方法面临着本质的扩容难题:随着系统组件的增加,知识维护的复杂度呈线性甚至指数级增长(O(n))。文档格式的异构性、内容的冲突以及召回的准确率,都成为了限制 Agent 性能的瓶颈。

另一派则是"自顶向下"的端到端进化流派。这一派借鉴了 GPT 系列模型"从海量数据中涌现智能"的思路:不再依赖人工预设的规则,而是让系统在与环境的交互中直接学习。正如传统 NLP 中基于语法规则的方法被端到端训练取代一样,CloudMate 选择了这条路径——不预设"怎么做",而是基于结果反馈,让系统在不断的尝试中探索出最优解。

兆祥指出,要实现这种端到端的自进化,系统必须构建一个完整的闭环:评估筛选策略,变异生成路径,回测保障安全。三者缺一不可。

Cloudmate已部署上百个agent实例，每周处理上万次故障分析请求。在这篇文章中，我们通过分享会上的内容，逐一拆解这三个模块在CloudMate中的实现。看到这三个模块如何协同工作，形成一个持续进化的完整系统。

## 评估:定义能力的边界

在开放的运维环境中,评估 Agent 的表现远比评估传统 NLP 任务复杂。Anthropic 在 2025 年的博客中Demystifying Evals for AI Agents指出,Agent 评估面临三大挑战:输出的非确定性、任务定义的歧义性以及执行环境的副作用。如果评估不准,很难维护Agent系统的长期质量。

CloudMate 为此构建了一套客观指标与主观逻辑并行的双轨评估体系,旨在从探索中挑选出成功的轨迹并进行内化。

### 1. 客观指标:效率与结果的量化

这是评估的基础层,主要关注执行层面的统计数据:

- 任务完成率:是否在规定时间内输出了明确的结论?
- 工具调用效率:是否存在重复调用、无效参数或死循环?
- 端到端耗时:从告警触发到给出根因的时间消耗。

### 2. 主观逻辑:基于证据链的推理审查

这是 CloudMate 评估体系的核心创新。在运维诊断中,结论正确并不代表过程正确(比如Agent 可能"猜"中根因)。因此,CloudMate 引入了高阶大模型作为"裁判",对 Agent 的推理过程进行审计。

核心审查维度包括:

- 证据完备性:Agent 做出的每一个推断,是否都有明确的观测数据作为支撑?
- 逻辑自洽性:推理步骤之间是否存在因果断裂?
- 意图理解:Agent 是否正确理解了用户的模糊指令?

通过这种双轨评分,系统能够精准地筛选出那些"低分案例"。这些案例是系统进化的"种子",直接触发下一阶段的变异流程。

## 变异：生成高质量候选轨迹

当评估模块锁定了"待修复"的故障案例后，CloudMate 启动变异流程。由于 Agent 的探索运行时间长，成本也较高，完全无先验的随机探索不仅耗费巨大且效果不佳。因此在 CloudMate 中，"变异"并不只是随机游走，而是有方向地在未知解空间中寻找最优策略。在这一步中，CloudMate 主要采用了结合外部知识增强的并行探索和专家引导两种互补的路径生成策略。

### 1. 并行探索：基于算力与外部知识的定向寻优

对于大多数可定义状态的故障，CloudMate 采用大规模并行采样策略。系统在沙箱环境中并发启动多个 Agent 实例。为了扩展搜索空间，系统一方面会调整大模型的生成随机性参数或更换底层模型；另一方面，是引入海量的外部知识库进行定向检索。

软件的运行逻辑最终沉淀在工程资产中。当 Agent 缺乏排查思路时，系统会驱动不同的 Agent 实例向外拓展，主动搜索海量的项目代码库、由代码自动生成的系统设计说明以及项目专属的文档库。这意味着未知的排查策略被转化为了对已知确定性文档的检索应用。

以"数据库连接池耗尽"场景为例，传统的单一 Agent 可能陷入"检查配置 -> 建议扩容"的局部最优解。而在结合了外部知识的并行探索模式下，系统会生成多条差异化路径：

- 路径 A：聚焦资源配置，建议增加最大连接数配置。（评估：失败，治标不治本）
- 路径 B：检索近期的代码提交记录，发现某次代码变更修改了特定 API 的连接释放逻辑，导致调用延迟极高。（评估：存疑）
- 路径 C：检索团队的数据库运维规范文档，结合查询慢查询日志，发现某条 SQL 缺少规范要求的索引导致连接堆积。（评估：成功，定位根因）

通过引入外部代码与文档作为补充，极大地收敛了无效的随机尝试。这类通过大规模采样获取高质量轨迹的思路，在许多其它Agent和大模型系统的策略也有采用。如 DeepSeekMath-V2在的自验证框架中，系统通过引导下的大量多次生成参考答案再过滤的方式来突破单一模型的能力上限。稳定的评估能力，加上由外部知识库提供的高质量探索依据，使得系统能够有效捕获常规手段难以生成的正确排查路径。

### 2. 专家引导:行为克隆+反向推理

另一方面，对于一些难以处理的复杂故障，单纯的随机探索效率极低。此时，CloudMate 引入人机协同机制。当人类专家介入处理时，系统会在后台记录其完整的操作序列——查看了哪些监控面板、执行了哪些 grep 命令。这些高置信度的轨迹是 Agent 学习的最佳样本。

系统将专家的操作记录作为提示输入给 Agent,要求其生成:"为什么专家在这一步选择了查询慢日志?"通过这种反向推理,Agent 能够将人类的隐性直觉显性化,转化为可执行的逻辑链条。

### 3. 知识收敛：差异分析与规则提取

单纯的成功路径只是个例，必须泛化为通用知识。系统引入一个独立的审核模型，对比"原失败路径"与"新成功路径"的差异，并将关键差异点（如"必须检查慢日志"）蒸馏为结构化的知识规则，等待并入主库。

至此，一个未知的故障案例被转化为了一条新增的知识补丁。然而，这条新生成的规则虽然在当前案例中有效，是否会对其他场景产生副作用仍是未知数。为了防止新知识的引入导致旧能力的退化，这条规则必须在并入主库前接受系统的沙箱回测。

## 回测：自动化验证知识增量

变异产生的新知识在并入主库前，本质上是一个局部最优解，仅针对当前故障有效。为了确保该知识具有泛化能力，且不破坏系统原有的能力结构，必须经历完整的回归测试流程。

回测模块的核心职能是质量把关：防止 Agent 为了解决新问题 A，导致旧问题 B 的处理能力退化，从而保证知识库的每一次迭代都是正向的。

### 全量回归与能力防退化

CloudMate 建立了一套类似于软件工程持续集成的自动化流水线。核心组件是基准案例库，其中存储了大量历史已解决的典型故障案例。

每次变异模块提交"知识更新请求"时，系统会自动触发全量回归：

- 加载新知识：Agent 实例加载包含新规则的知识库。
- 基准测试：Agent 必须重新运行基准库中的所有历史案例。
- 判定逻辑：系统对比新旧版本的通过率。如果新规则导致任何一个历史案例的成功率下降，该更新将被立即驳回，并退回变异模块进行修正。

这一机制确保了系统能力的持续积累且不倒退。它让运维系统的进化脱离了对人工审核的依赖，通过确定性的自动化测试，保证了 Agent 行为的全局稳定性。

### 工程挑战：环境解耦与快照仿真

在运维领域实施上述回归测试，面临着比代码测试更严峻的挑战：数据的时效性与环境的动态性。

去年的故障案例，依赖的是当时的日志、指标和网络拓扑。而现网环境是实时变化的，直接重跑历史案例，Agent 会请求当前的监控系统，导致数据不一致，产生大量的误报。

为了解决这一问题，CloudMate 构建了一套基于快照的沙箱仿真架构：

- 数据快照：在基准案例被录入时，系统不仅记录 Agent 的对话逻辑，还利用中间层协议，捕获了所有工具调用的原始返回数据。
- 沙箱隔离：在回测执行时，Agent 被隔离在封闭的沙箱环境中。Agent 发出的所有查询请求会被系统拦截。
- 模拟回放：系统不访问实时监控，而是直接从快照中读取当时的 JSON 数据返回给 Agent。

通过这种方式，系统成功实现了测试执行与时间维度的解耦。Agent 能够在一个被冻结的"历史切片"中进行推理，确保了基准测试的可重复性与客观性。

## 构建确定性的进化闭环

至此，CloudMate 构建了一个完整的自进化实体。评估、变异、回测三个模块构成了一个首尾相接的工程闭环，确保持续集成的稳定性。评估模块提供验收标准，为变异产生的候选解法提供筛选标准，确保知识生成时有稳定的输入。变异提供候选解，系统利用并行探索或者专家路径分析在解空间中进行有向搜索。为知识提取准备了大量可行的解，不断探索更新的答案空间。而回测则提供边界约束，通过沙箱环境下的全量回归，对候选知识进行严格的逻辑验证。剔除了不稳定的噪声，确保新引入的规则满足系统的全局一致性约束，解决了"改进是否安全"的问题。

## 局限性和挑战

尽管 CloudMate 构建了理论上的自进化闭环，但在实际落地的过程中，系统仍面临着算力成本、数据依赖与复杂性理论等多维度的挑战。作为早期尝试，CloudMate 目前在以下几个方面仍存在显著的局限性：

1. **探索机制的依赖偏差**：尽管系统在并行探索模块中引入了外部代码库与文档的定向检索，试图打破纯粹依赖模型随机性的局限，但在当前的生产实践中，复杂知识的内化仍高度依赖于专家经验。因此，目前的并行探索在处理疑难杂症时更多作为线索辅助，高质量排查轨迹的生成与确立仍需人机协同来完成。未来如何引入更多样化的策略生成算法，进一步提升机器在海量外部知识中的自主推理与收敛能力，从而实质性减少对专家直觉的依赖，是系统亟待突破的方向。Agent并行探索也是最近学术界研究的热点，可以期待一些沉淀下来的最佳实践。

2. **冷启动与基准构建成本**：系统的安全性依赖于回测，而回测的有效性依赖于一个高质量的基准案例库。兆祥在分享中坦言，案例库的维护是"成本最高"的环节。为了确保回测的准确性，每一个基准案例都需要专家进行清洗、标注和确认。在系统冷启动阶段，这意味着巨大的人力投入。虽然团队正在探索利用 LLM 辅助生成文档和背景知识以降低门槛，但目前这一过程仍未实现完全的自动化。

3. **沙箱快照的完备性与时序性挑战**：已有的沙箱快照的维护仍面临两个维度的挑战：首先是数据的完备性。快照主要依赖"历史多次运行记录"和"大模型预测"来收集接口返回数据。然而，由于 Agent 具备自进化能力，未来的 Agent 可能会探索出全新的排查路径，调用快照中未曾预测到的接口，或者使用了完全不同的查询参数。当这种"预测外"的调用在回归测试中发生时，沙箱无法提供有效的返回数据。这种情况下，系统难以直接通过执行结果判断新路径的对错，往往需要引入大模型从其他逻辑角度进行辅助评估，这增加了回测的不确定性。其次是数据的时序性挑战。虽然大部分监控和日志数据带有时间标签，回放不会出错，但部分运维资源数据缺乏时间维度。CloudMate 目前的缓解机制是在创建快照时判断数据是否易变，若发生变化则触发告警。但根本的解决途径仍依赖于底层数据治理——例如，将资源图谱等重要且易变的静态数据全面改造为带有时间维度的可观测数据，才能从根本上消除时序性误差。

4. **知识库的长期收敛性**：虽然自进化架构旨在解决人工维护 O(n) 复杂度的问题，但端到端自动化并不意味着大模型能天然的解决知识库的熵增。随着自动生成的规则不断累积，知识库内部可能出现逻辑冲突、规则冗余或过拟合现象，导致大模型创建的新知识难以通过回测，最终导致系统停止进化。在长期自动化执行的情况下，系统是否能够保持知识库的一致性，仍是一个需要长期观察的开放性问题。

## 结语：E2E 与工程治理的边界

CloudMate 的实践向我们揭示了一个被长期忽视的视角：AI Agent 的核心竞争力不仅在于部署时的静态能力上限，也在于其运行后的进化速率。软件系统是在持续迭代的。一个无法随被运维对象共同进化的 Agent，在生产环境下是难以持续的。CloudMate 通过构建"评估（发现偏差）- 变异（探索新知）- 回测（收敛边界）"的完整闭环，尝试端到端的解决这一根本性矛盾，让 Agent 具备了与软件系统共同进化的能力。

然而，我们必须清醒地认识到，这种端到端的自进化机制并非运维领域的"银弹"。E2E 模式虽然试图自动化的解决人工维护知识库的 O(n) 复杂度问题，但它并未消除复杂性本身，而是将其转移到了新的维度——如何构建高保真的仿真环境、如何设计低成本的评估函数、以及如何收敛自动生成的知识熵增。实际上又回到了原有的"自底向上"的确定性治理与"自顶向下"的 E2E 进化，两者的边界究竟在何方？

对于静态、强规则、低容错的场景（如核算系统、基础网络配置），传统的、基于确定性代码的治理体系依然是不可替代的基石。而对于动态、模糊、高维度的场景（如微服务故障定位、性能调优），自进化 Agent 提供了一种突破瓶颈的可能。

CloudMate 作为一个早期的探索者，在引起人们对于新范式的关注的同时，也展现了 E2E 模式在冷启动成本、环境依赖与长期收敛性上的诸多挑战。它指出了在缺乏标注数据的动态环境中实现知识自动化生产的一条可行道路，但也提醒我们，这条路依然充满了需要严肃对待的工程难题。

未来的运维体系，不会是纯粹的人为设计或纯粹的Agent自治，而是两者的某种有机融合。在这个过程中，探索 E2E 能力的上限与工程治理的底线，将是整个行业需要共同面对的长期课题。

---

整理自Agent管理学论坛第10期: 自进化的Agent运维系统-腾讯云CloudMate
